# Ollama Setup Guide

## –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Ollama

### –õ–æ–∫–∞–ª—å–Ω–æ (–¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏/—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)

```bash
# Linux/Mac
curl -fsSL https://ollama.ai/install.sh | sh

# Windows
# –°–∫–∞—á–∞—Ç—å —Å https://ollama.ai/download
```

–ü–æ—Å–ª–µ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –∑–∞–ø—É—Å—Ç–∏—Ç—å:
```bash
ollama serve
```

## –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –º–æ–¥–µ–ª–∏

### 1. Qwen 2.5 (–†–ï–ö–û–ú–ï–ù–î–£–ï–¢–°–Ø)

**Qwen2.5:14B** - –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å –∫–∞—á–µ—Å—Ç–≤–∞ –∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
```bash
ollama pull qwen2.5:14b
```

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- ‚úÖ –û—Ç–ª–∏—á–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ
- ‚úÖ –£–º–µ–µ—Ç —Å–ª–µ–¥–æ–≤–∞—Ç—å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º
- ‚úÖ –°—Ä–µ–¥–Ω–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ VRAM (~9-10 GB)
- ‚úÖ –•–æ—Ä–æ—à–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏

**Qwen2.5:7B** - –û–±–ª–µ–≥—á–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è
```bash
ollama pull qwen2.5:7b
```
- –¢—Ä–µ–±—É–µ—Ç ~5-6 GB VRAM
- –•–æ—Ä–æ—à–æ –¥–ª—è —Å–ª–∞–±—ã—Ö GPU

**Qwen2.5:32B** - –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ
```bash
ollama pull qwen2.5:32b
```
- –¢—Ä–µ–±—É–µ—Ç ~20-22 GB VRAM
- –õ—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ –æ—Ç–≤–µ—Ç–æ–≤

### 2. Llama 3.1 (–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞)

**Llama3.1:8B** - –•–æ—Ä–æ—à–∏–π –≤–∞—Ä–∏–∞–Ω—Ç –¥–ª—è —Å–ª–∞–±—ã—Ö GPU
```bash
ollama pull llama3.1:8b
```
- –¢—Ä–µ–±—É–µ—Ç ~6 GB VRAM
- –•–æ—Ä–æ—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ, –Ω–æ —Ö—É–∂–µ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫ —á–µ–º —É Qwen

### 3. Gemma 2 (Google)

**Gemma2:9B** - –ö–æ–º–ø–∞–∫—Ç–Ω–∞—è –∏ –±—ã—Å—Ç—Ä–∞—è
```bash
ollama pull gemma2:9b
```
- –¢—Ä–µ–±—É–µ—Ç ~6-7 GB VRAM
- –ë—ã—Å—Ç—Ä–∞—è, –Ω–æ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫ —Å–ª–∞–±–µ–µ

## –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—é

### –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è (Qwen2.5:7B)
- **GPU:** NVIDIA GTX 1660 Ti (6 GB VRAM)
- **RAM:** 16 GB
- **–î–∏—Å–∫:** 10 GB —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ –º–µ—Å—Ç–∞

### –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ (Qwen2.5:14B)
- **GPU:** NVIDIA RTX 3060 (12 GB VRAM) –∏–ª–∏ RTX 4060 Ti
- **RAM:** 16 GB
- **–î–∏—Å–∫:** 15 GB —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ –º–µ—Å—Ç–∞

### –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ (Qwen2.5:32B)
- **GPU:** NVIDIA RTX 4090 (24 GB VRAM) –∏–ª–∏ RTX 3090
- **RAM:** 32 GB
- **–î–∏—Å–∫:** 25 GB —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ –º–µ—Å—Ç–∞

## –í–∞—Ä–∏–∞–Ω—Ç—ã —Ö–æ—Å—Ç–∏–Ω–≥–∞

### 1. Vast.ai (–†–ï–ö–û–ú–ï–ù–î–£–ï–¢–°–Ø)

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- üí∞ –î–µ—à–µ–≤–ª–µ Runpod –≤ 2-3 —Ä–∞–∑–∞
- üåç –ú–Ω–æ–≥–æ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö GPU
- ‚ö° –ü—Ä–æ—Å—Ç–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å

**–¶–µ–Ω—ã (–ø—Ä–∏–º–µ—Ä–Ω—ã–µ):**
- RTX 3060 (12 GB): $0.15-0.25/—á–∞—Å (~$3.6-6/–¥–µ–Ω—å)
- RTX 3090 (24 GB): $0.30-0.45/—á–∞—Å (~$7-11/–¥–µ–Ω—å)
- RTX 4090 (24 GB): $0.60-0.90/—á–∞—Å (~$14-22/–¥–µ–Ω—å)

**–ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:**
1. –ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å—Å—è –Ω–∞ https://vast.ai
2. –í—ã–±—Ä–∞—Ç—å GPU —Å –Ω—É–∂–Ω—ã–º VRAM
3. –í—ã–±—Ä–∞—Ç—å –æ–±—Ä–∞–∑ —Å Docker + CUDA
4. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å Ollama –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ
5. –û—Ç–∫—Ä—ã—Ç—å –ø–æ—Ä—Ç 11434
6. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `OLLAMA_URL=http://your-vast-instance:11434`

### 2. RunPod

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- üöÄ –ë—ã—Å—Ç—Ä–æ–µ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ
- üì¶ –ï—Å—Ç—å –≥–æ—Ç–æ–≤—ã–µ —à–∞–±–ª–æ–Ω—ã
- üîß –£–¥–æ–±–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å

**–¶–µ–Ω—ã (–ø—Ä–∏–º–µ—Ä–Ω—ã–µ):**
- RTX 3090: $0.44-0.69/—á–∞—Å (~$11-17/–¥–µ–Ω—å)
- RTX 4090: $0.79-1.19/—á–∞—Å (~$19-29/–¥–µ–Ω—å)

**–î–æ—Ä–æ–∂–µ Vast.ai, –Ω–æ –ø—Ä–æ—â–µ –≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏**

### 3. Lambda Labs

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- üéØ –°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞ ML
- ‚ö° –ë—ã—Å—Ç—Ä—ã–µ GPU
- üìä –ü—Ä–µ–¥—Å–∫–∞–∑—É–µ–º—ã–µ —Ü–µ–Ω—ã

**–¶–µ–Ω—ã:**
- A100 (40 GB): $1.10/—á–∞—Å (~$26/–¥–µ–Ω—å)
- A6000 (48 GB): $0.80/—á–∞—Å (~$19/–¥–µ–Ω—å)

### 4. –õ–æ–∫–∞–ª—å–Ω–æ (–¥–æ–º–∞)

**–ï—Å–ª–∏ –µ—Å—Ç—å –ø–æ–¥—Ö–æ–¥—è—â–∞—è GPU:**
- üí∞ –ë–µ—Å–ø–ª–∞—Ç–Ω–æ –ø–æ—Å–ª–µ –ø–æ–∫—É–ø–∫–∏
- üîí –ü–æ–ª–Ω—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å
- üì∂ –ù–µ—Ç –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞

**–ú–∏–Ω—É—Å—ã:**
- ‚ö° –í—ã—Å–æ–∫–æ–µ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ —ç–Ω–µ—Ä–≥–∏–∏
- üîä –®—É–º –æ—Ç GPU
- üå°Ô∏è –ù—É–∂–Ω–æ –æ—Ö–ª–∞–∂–¥–µ–Ω–∏–µ

## –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –¥–ª—è –æ–±–ª–∞—á–Ω–æ–≥–æ —Ö–æ—Å—Ç–∏–Ω–≥–∞

### Vast.ai –ø—Ä–∏–º–µ—Ä

```bash
# –í –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ –Ω–∞ Vast.ai
apt update && apt install -y curl
curl -fsSL https://ollama.ai/install.sh | sh

# –ó–∞–ø—É—Å—Ç–∏—Ç—å Ollama
ollama serve &

# –°–∫–∞—á–∞—Ç—å –º–æ–¥–µ–ª—å
ollama pull qwen2.5:14b

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å
curl http://localhost:11434/api/tags
```

### –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Petal

–í `.env` —Ñ–∞–π–ª–µ:
```env
OLLAMA_URL=http://your-vast-instance-ip:11434
OLLAMA_MODEL=qwen2.5:14b
```

## –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

### 1. –ö–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π

Ollama –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∫–≤–∞–Ω—Ç–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Ä—Å–∏–∏:
- `q4_0` - 4-bit –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è (—Å–∞–º–∞—è –±—ã—Å—Ç—Ä–∞—è, ~50% –º–µ–Ω—å—à–µ VRAM)
- `q5_0` - 5-bit –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è (–±–∞–ª–∞–Ω—Å)
- `q8_0` - 8-bit –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è (–ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ)

### 2. –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–µ –æ–∫–Ω–æ

–í –∫–æ–¥–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ `num_ctx: 8192`. –ú–æ–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å:
- 4096 - –º–∏–Ω–∏–º—É–º –¥–ª—è –±–∞–∑–æ–≤–æ–π —Ä–∞–±–æ—Ç—ã
- 8192 - —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
- 16384 - –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤ (—Ç—Ä–µ–±—É–µ—Ç –±–æ–ª—å—à–µ VRAM)

### 3. Batch size

Ollama –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç, –Ω–æ –º–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å —á–µ—Ä–µ–∑ env:
```bash
OLLAMA_NUM_PARALLEL=4  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
```

## –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å—Ç–æ–∏–º–æ—Å—Ç–∏

### –ú–µ—Å—è—á–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å (24/7)

**Vast.ai:**
- RTX 3060: $110-180/–º–µ—Å—è—Ü
- RTX 3090: $215-325/–º–µ—Å—è—Ü
- RTX 4090: $430-650/–º–µ—Å—è—Ü

**RunPod:**
- RTX 3090: $320-500/–º–µ—Å—è—Ü
- RTX 4090: $580-860/–º–µ—Å—è—Ü

**–õ–æ–∫–∞–ª—å–Ω–æ (RTX 3060):**
- –ü–æ–∫—É–ø–∫–∞ GPU: $250-350 (–µ–¥–∏–Ω–æ—Ä–∞–∑–æ–≤–æ)
- –≠–ª–µ–∫—Ç—Ä–∏—á–µ—Å—Ç–≤–æ: ~$15-25/–º–µ—Å—è—Ü (–≤ –†–æ—Å—Å–∏–∏)

## –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

### –î–ª—è –Ω–∞—á–∞–ª–∞ (—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ):
- üéØ **–ú–æ–¥–µ–ª—å:** Qwen2.5:7B
- üíª **–•–æ—Å—Ç–∏–Ω–≥:** –õ–æ–∫–∞–ª—å–Ω–æ –∏–ª–∏ Vast.ai (RTX 3060)
- üí∞ **–°—Ç–æ–∏–º–æ—Å—Ç—å:** $0 (–ª–æ–∫–∞–ª—å–Ω–æ) –∏–ª–∏ ~$120/–º–µ—Å—è—Ü

### –î–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞ (–∫–∞—á–µ—Å—Ç–≤–æ):
- üéØ **–ú–æ–¥–µ–ª—å:** Qwen2.5:14B
- üíª **–•–æ—Å—Ç–∏–Ω–≥:** Vast.ai (RTX 3090)
- üí∞ **–°—Ç–æ–∏–º–æ—Å—Ç—å:** ~$250/–º–µ—Å—è—Ü

### –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ:
- üéØ **–ú–æ–¥–µ–ª—å:** Qwen2.5:32B
- üíª **–•–æ—Å—Ç–∏–Ω–≥:** Vast.ai (RTX 4090)
- üí∞ **–°—Ç–æ–∏–º–æ—Å—Ç—å:** ~$500/–º–µ—Å—è—Ü

## –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞: –ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–¥—Ö–æ–¥

–ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:
- **–õ–æ–∫–∞–ª—å–Ω–æ** –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
- **–û–±–ª–∞–∫–æ** (Vast.ai) –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞

–ò–ª–∏:
- **–õ–µ–≥–∫–∞—è –º–æ–¥–µ–ª—å** (Qwen2.5:7B) –¥–ª—è –ø—Ä–æ—Å—Ç—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
- **–¢—è–∂–µ–ª–∞—è –º–æ–¥–µ–ª—å** (Qwen2.5:32B) –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–¥–∞—á

## –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥

–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç–∞—Ç—É—Å Ollama:
```bash
curl http://localhost:11434/api/tags
```

–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –º–æ–¥–µ–ª–∏:
```bash
ollama list
```

–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU:
```bash
nvidia-smi
```

## Troubleshooting

### Ollama –Ω–µ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è
```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø—Ä–æ—Ü–µ—Å—Å
ps aux | grep ollama

# –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å
pkill ollama
ollama serve
```

### –ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è
```bash
# –£–¥–∞–ª–∏—Ç—å –∏ –∑–∞–≥—Ä—É–∑–∏—Ç—å –∑–∞–Ω–æ–≤–æ
ollama rm qwen2.5:14b
ollama pull qwen2.5:14b
```

### –ù–µ—Ö–≤–∞—Ç–∫–∞ VRAM
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–µ–Ω—å—à—É—é –º–æ–¥–µ–ª—å (7B –≤–º–µ—Å—Ç–æ 14B)
- –£–º–µ–Ω—å—à–∏—Ç—å `num_ctx` –¥–æ 4096
- –ó–∞–∫—Ä—ã—Ç—å –¥—Ä—É–≥–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–µ GPU
